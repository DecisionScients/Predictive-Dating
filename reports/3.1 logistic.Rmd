<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {
equationNumbers: {
autoNumber: "all",
formatNumber: function (n) {return '3.1.'+n}
}
}});</script>

## Logistic Regression
Typically used in binary classification problems, logistic regression or logit regression estimates the probability of a binary response based upon one or more predictor variables. Multinomial logistic regression is a generalization of binary logistic regression for response variables with greater than two levels. 

### Learning Objectives
Selecting and implementing the “right” machine learning algorithm to predict the future based upon past data is a necessary, but not sufficient, condition for success as a data scientist. Data science and the outcomes it produces may be complex and difficult to explain.  Yet, the effective data scientist must be equally facile at explaining her approach and findings to both colleagues and non-technical stakeholders. 

That said, by the end of this section, you will be able to:

1. Describe the Logistic Regression method and characterize its assumptions, advantages and disadvantages.    
2. Characterize problem sets for which logistic regression is best suited.   
3. Define the logistic regression hypothesis and cost functions for binary and multinomial classification problems.  
4. Explain techniques, such as batch gradient descent and stochastic gradient descent, used to estimate the parameters of the logistic function.  
5. Optimize a logistic regression in python using the scikit-learn package.   
6. Evaluate the performance of a classifier based upon logistic regression.  


### Why Logistic Regression?
We use the logistic regression model when we wish to model the posterior probability that $Y$ belongs to a particular group. But wait! Why do we need logistic regression when we can simply model $Y$ directly using linear regression methods?  Great question! 

#### Posterior Probabilities are Not Linear With Respect to the Predictors
To illustrate the point, consider the problem of predicting the probability of default on a credit card, based upon the balance [@James2017]. 

```{python default}
# Prepare data
df = pd.read_csv(os.path.join(directories.EXTERNAL_DATA_DIR, 'Default.csv'),
                 encoding="Latin-1", low_memory=False)
df['Probability of Default'] = np.where(df['default'] == 'No',0, 1)
df['Balance'] = df['balance']

# Set plot defaults
sns.set(style="whitegrid", font_scale=2)
sns.set_palette("GnBu_d")

# Render plots
fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2)
sns.regplot(x='Balance', y='Probability of Default', data=df, ci=None, ax=ax1)
sns.regplot(x='Balance', y='Probability of Default', data=df, ci=None,logistic=True, ax=ax2)
ax1.set_title(label='Linear Regression')
ax2.set_title(label='Logistic Regression')
fig.savefig("./reports/figures/default.png")
plt.close(fig)
```
![](../reports/figures/default.png)
`r kfigr::figr(label = "default", prefix = TRUE, link = TRUE, type="Figure")`: Probability of Default by Balance 

The left plot in `r kfigr::figr(label = "default", prefix = TRUE, link = TRUE, type="Figure")`  shows the estimated probability of default using linear regression. we see that the classes are linearly separable; however, the linear regression returns negative probabilities! On the right, we have the predicted probability of default using a logistic regression based upon the logistic, or sigmoid function.  All probabilities are between 0 and 1.

This illustrates several properties of the posterior probability distribution.   

1. Probabilities must be bounded between 0 and 1 for all real values of the predictor space.  There should be no credit card balance for which the probability of default is less than zero or greater than one.  
2. Probability must increase monotonomically for increasing values in the predictor space. That is to say that the probability of default must not decrease with increasing balances.  
3. Hence, the probability distribution is actually S-shaped, rather than linear over the predictor space.  

#### Linear Regression Implies Ordering in the Responses
Consider a supervised learning problem to predict the psychiatric disorder of a patient based upon electronic medical records and transcripts of past patient interviews. Suppose that there are three possible diagnoses: schizophrenia, major depressive disorder, and capgras delusion. We could encode these values as a quantitative response variable, $Y$, as follows:

$$
Y=\begin{cases}
1 \text{ if schizophrenia;} \\
2 \text{ if major depressive disorder;} \\
3 \text{ if capgras delusion.}
\end{cases}
$$
Using this coding, we could use least squares to fit a linear regression model to predict $Y$ on the basis of a set of predictors $X_1,X_2,\dots, X_p$. Unfortunately, this coding implies an ordering on the outcomes that may not exist. For instance, we could have selected an equally reasonable coding,
$$
Y=\begin{cases}
1 \text{ if major depressive disorder;} \\
2 \text{ if capgras delusion;} \\
3 \text{ if schizophrenia.}
\end{cases}\label{psych}
$$
This encoding would imply a completely different relationship between the predictors and response, resulting in very different predictions on test data.

#### Linear Regression Implies Equal Difference Between Responses
Linear regression also insists that the distances between the responses match the difference between the encodings. For instance, the encoding in $\ref{psych}$ implies that the difference between major depressive disorder and capgras delusion equals the difference between capgras delusion and schizophrenia. In this particular example, the differences between the categorical responses have no meaning. 

These scenarios illuminate the point. In many cases, there is no practical way to convert a categorical response with more than two levels into a quantitative response for linear regression. Hence, we seek to use methods that are truly suited for the qualitative response values we seek to model. If we are interested in modeling the probability that an observation belongs to a particular group, our model must provide a monotonically increasing probability between 0 and 1 for all possible values of the predictor space.

### What is Logistic Regression?
Let's first consider the binary classification context, where $y \in \lbrace0,1\rbrace$. Logistic or logit regression is a statistical model used to estimate the parameters of the sigmoid function.

#### Sigmoid Function  
The sigmoid function is defined as:
$$g(z)=\frac{1}{1+e^{-z}}\label{sigmoid}$$


```{python sigmoid}
# Create data
x = np.linspace(-10,10,100)

#sigmoid = lambda x: 1 / (1 + np.exp(-x))
def sigmoid(x):
    return (1 / (1 + np.exp(-x)))
    
# Set plot defaults
sns.set(style="whitegrid", font_scale=2)
sns.set_palette("GnBu_d")

# Render plots
fig, ax = plt.subplots()
sns.lineplot(x=x, y=sigmoid(x), ax=ax)
ax.set_title(label='Logistic (Sigmoid) Function')
ax.text(4, 0.8, r'$g(z)=\frac{1}{1+e^{-z}}$')
fig.savefig("./reports/figures/sigmoid.png")
plt.close(fig)

```

![](../reports/figures/sigmoid.png)
`r kfigr::figr(label = "sigmoid", prefix = TRUE, link = TRUE, type="Figure")`: Sigmoid Function

The sigmoid function graphically depicted in `r kfigr::figr(label = "sigmoid", prefix = TRUE, link = TRUE, type="Figure")` is an S-shaped curve, with several appealing characteristics for modeling the probability that an observation belongs to a particular class. 

1. The sigmoid function is a real function defined for all real input values.  
2. It is bounded horizontally, typically from 0 to 1, for $x\rightarrow \pm \infty$, thereby ensuring that all probabilities lie between 0 and 1.  
3. The sigmoid function has a non-negative differential at each point and therefore returns monotonically increasing values with increasing inputs. 

#### Hypothesis Function
For logistic regression, we define our hypothesis function $h_\theta$, as a special case application of the sigmoid function:
$$h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-(\theta^TX)}},$$
where:  

* $\theta \in \mathbb{R}^{n\times (p+1)}$ is the matrix of coefficients,  
* $x \in \mathbb{R}^{n\times (p+1)}$ is the matrix of inputs, and   
* $g(z)$ is defined as in $\ref{sigmoid}$. 

Hence, $g(\theta^Tx)$ gives us the probability that our class assignment is 1, in the case of a binary classification of $Y\in \lbrace 0,1\rbrace$.

In order to get our discrete 0 or 1 classification, we translate the output of $g(\theta^Tx)$ as follows:
$$
y = \begin{cases}
1, \space if \space h_\theta(x) \ge 0.5 \\
0, \space if \space h_\theta(x) \lt 0.5
\end{cases}
$$
Recall, the sigmoid function, $$g(z)=\frac{1}{1+e^{-z}},$$
computes an output greater than or equal to 0.5, when the input is greater than or equal zero. Concretely,  

* $z=0, e^0=1 \implies g(z)=1/2$  
* $z\rightarrow\infty, e^{-\infty}\rightarrow0\implies g(z)=1$   
* $z\rightarrow-\infty, e^{\infty}\rightarrow \infty \implies g(z)=0$   

So, if $\theta^TX \ge 0$, this means that $h_\theta(x)=g(\theta^Tx) \ge 0.5$ .  From these statements we can now say:  

* $\theta^TX \ge 0 \implies y=1$   
* $\theta^TX \lt 0 \implies y=0$   

From this, we can obtain the **decision boundary** which separates the area where $y=0$ and where $y=1$. For instance, let:
$$
\theta = 
\begin{bmatrix}
5\\-1\\0
\end{bmatrix}
$$
To obtain the decision boundary, we simply plug the values for $\theta$ into our logistic function.
$$y = 1, \space if\space 5x_0+(-1)x_1+0x_2 \ge 0,$$
where $x_0 = 1$. Solving the inequality, we have:
$$5-x_1 \ge 0$$
In this case, our decision boundary is a straight vertical line placed on the graph where $x_1=5$. Everything to the left of that denotes $y=1$, and everything to the right implies $y=0$.

### How Do We Fit Logistic Regression Models?
Given a training set, how do we learn the parameters $\theta$? We first define a **cost function**, a measure for how close our hypothesis function $h(x)$ is to the true response values. Then, we use a search function that starts with an "initial guess" for $\theta$, then repeatedly makes changes in $\theta$ in order to minimize the cost function until, *hopefully*, the algorithm converges at a parameter set $\theta$ that minimizes the cost function. 

#### Cost Function
We first define our cost function for logistic regression:  
$$J(\theta)=\frac{1}{n}\displaystyle\sum_{i=1}^nCost(h_\theta(x_i),y_i),$$
where:
$$
\begin{matrix}
Cost(h_\theta(x),y)=-log(h_\theta(x)) & if \space y=1 \\
Cost(h_\theta(x),y)=-log(1-h_\theta(x)) & if \space y=0
\end{matrix}
$$
```{python cost}
# Prepare data
x = np.linspace(0,1,100)
y0 = -np.log(1-x)
y1 = -np.log(x)

# Set plot defaults
sns.set(style="whitegrid", font_scale=2)
sns.set_palette("GnBu_d")

# Render plots
fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2)
sns.lineplot(x=x, y=y0, ax=ax1)
sns.lineplot(x=x, y=y1, ax=ax2)
ax1.set_title(label='Cost if y = 0')
ax2.set_title(label='Cost if y = 1')
fig.suptitle("Cost Function")
fig.savefig("./reports/figures/cost.png")
plt.close(fig)
```

`r kfigr::figr(label = "cost", prefix = TRUE, link = TRUE, type="Figure")` graphically depicts the cost function for both values of $y$.

![](../reports/figures/cost.png)
`r kfigr::figr(label = "cost", prefix = TRUE, link = TRUE, type="Figure")`: Logistic Regression Cost Function

If our correct answer is $y=0$, then the cost function will be 0 if our logistic function also outputs 0.  If our logistic function approaches 1, then the cost function approaches infinity. Conversely, if our correct answer is $y=1$, then the cost function will be 0 if our logistic function computes 1. If the logistic function approaches 0, then the cost function will approach infinity.  Note, that writing the cost function this way guarantees that $J(\theta)$ is convex for logistic regression.

Using the following representation, we can compress our cost function's two conditional cases into one case:
$$Cost(h_\theta(x),y)=-(\underbrace{ylog(h_\theta(x))}_{(1)})-(\underbrace{(1-y)log(1-h_\theta(x)))}_{(2)}$$
Note that when $y=1$, term (2) is zero and when $y=0$, term (1) is zero. Neat trick, yes?

We can therefore express the entire cost function as follows:
$$J(\theta)=-\frac{1}{n}\displaystyle\sum_{i=1}^n[y_ilog(h_\theta(x_i))+(1-y_i)log(1-h_\theta(x_i))]$$
We can implement a vectorized version as follows:  

* $g(z)=\frac{1}{1+e^{-z}}$  
* $h=g(X\theta)$    
* $J(\theta)=\frac{1}{n}[-y^Tlog(h)-(1-y)^Tlog(1-h)]$    

`r h <- 'Estimating $\theta$'`
#### `r h`
Having defined our cost function, the next step is to identify a parameter set $\theta$ that minimizes the cost function. Generally speaking, there are two approaches we can pursue: the **analytic approach**, and the **iterative approach**. 

The analytic approach explicitly takes the derivative of the function with respect to $\theta$, sets it to zero and obtains the **normal equation**:
$$X^TX\theta=X^T\overrightarrow{y}.$$
Solving for $\theta$ gives us a closed form equation for the parameters $\theta$ that minimizes our cost function $J(\theta)$:
$$\theta=(X^TX)^{-1}X^T\overrightarrow{y}.$$
where:   
* $X$ is the matrix of input observations and   
* $y$ is the output vector.    

The problem with this approach is the time complexity of calculating $(X^TX)^{-1}$. Computing the inverse of an $n\times n$ matrix is  $O(n^3)$ and as $n$ increases it can take a very long time to finish. For small datasets ($n \lt 10,000$), the analytic approach might be practical; but, for most machine learning applications, the iterative approach is much faster.

The iterative approach starts with some 'initial guess' for $\theta$, then repeatedly changes $\theta$ to make $J(\theta)$ smaller, until *hopefully* it converges to a value of $\theta$ that minimizes $J(\theta)$. Next, we'll explore three widely used iterative optimization algorithms:  

* Gradient Descent,    
* Stochastic (Iterative) Gradient Descent, and
* The Newton-Raphson method.

#### Gradient Descent
Gradient descent is an iterative optimization algorithm for finding the minimum of a function. To learn the parameters $\theta$ that minimize our cost function $J(\theta)$, gradient descent starts with an initial $\theta$ then makes successive steps proportional to the *negative* *gradient* of the cost function at the current $\theta$. Hence, each step is in the direction of the steepest descent.

![](../reports/figures/gradient-descent.png)

`r kfigr::figr(label = "gradient_descent", prefix = TRUE, link = TRUE, type="Figure")`: Gradient Descent

`r kfigr::figr(label = "gradient_descent", prefix = TRUE, link = TRUE, type="Figure")` illustrates gradient descent for two separate 'initial guesses' of $(\theta_1, \theta_2)$. Where you finish *could* depend upon where you start. Convergence to different local minimums based upon an initial position is a characteristic of gradient descent. 

Let's define gradient descent more formally. Starting with some initial $\theta$, gradient descent repeatedly performs the following update:
$$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta).$$
Computing the partial derivative, we have:
$$\theta_j:=\theta_j-\frac{\alpha}{n}\displaystyle\sum_{i=1}^n(h_\theta(x_i)-y_i)x_{i,j}\space \forall j,$$
where the $\alpha$ term is the **learning rate**.  This update, called the **least mean squares** ($\mathbf{LMS}$) update rule, is performed simultaneously for all values of $j=0,\dots,p$, where $p$ is the number of predictors. Subtracting the gradient ensures that each update step is taken in the direction of the steepest decrease in $J$.

We can vectorize the implementation as follows:
$$\theta:=\theta=\frac{\alpha}{n}X^T(g(X\theta)-\overrightarrow{y})$$
This algorithm is also called *batch* gradient descent because it looks at every observation in the entire training set on every step. 

##### Advantages and Disadvantages of Gradient Descent
Gradient descent is a popular optimization algorithm for good reason.
1. It is simple and effective for most convex, differentiable optimization problems.   
2. Computationally efficient. No need to compute inverses, factorizations, or 2nd derivatives of large matrices.  
3. Works in spaces with any number of dimensions.  
4. Error gradients and convergence are highly stable.  

On the other hand, gradient descent may converge slowly or inaccurately.
1. Convergence may take too many iterations if the curvature for a function is very different in different directions.  
2. Each gradient step requires $O(np)$ operations ($n=sample size, p=number of covariates$). With modern computing, data sets with $n=10^6$ and $k=10^2$ may be fine, but datasets on the order of $n=10^{12}$ may be prohibitively expensive to process. 
3. A sub-optimal learning rate may throttle the convergence process. If the learning rate is too small, it will take too many iterations to converge. If it is too large, it may oscillate around a local minimum and never converge to a true minimum. 
4. Since the entire dataset must be held in memory, certain machine learning problems may be too memory intensive.    
5. Different initial starting points may result in different local minimums.

That said, gradient descent is the workhorse of iterative optimization algorithms in machine learning. It's simple, relatively fast, and effective method for function minimization. Next, let's review some implementation best practices.

##### Gradient Descent Implementation Best Practices
In the last section, we illuminated the importance of effective hyperparameter tuning. A learning rate that is too 





Next we will examine another algorithm which, oftentimes, arrives at a $\theta$ close to that which minimizes $J$ faster. 

##### Stochastic (Incremental) Gradient Descent
Consider the following algorithm:

  Loop {  
    for i=1 to n, {   
      $\qquad\theta_j:=\theta_j-\alpha(h_\theta(x_i)-y_i)x_{i,j}\space \forall j,$    
    }   
  }   

Here, we repeatedly run through the training set; however, unlike batch gradient descent, we update the parameters according to the gradient of the error with respect to that single observation only. Whereas batch gradient descent has to scan through the entire training set before taking a single step, stochastic gradient descent starts making progress right away.  As stated, stochastic gradient descent often arrives at $\theta$ close to the minimum much faster than batch gradient descent, but it may never 'converge'.  Depending upon the learning rate, the parameters may oscillate around the minimum of $J(\theta)$, but in practice, such approximations of the 'true' minimum or reasonably good. This is why stochastic gradient descent may be a better choice for large datasets.

##### Newton's Method
