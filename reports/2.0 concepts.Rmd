<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {
equationNumbers: {
autoNumber: "all",
formatNumber: function (n) {return '2.'+n}
}
}});</script>

# Machine Learning Core Concepts
In this section, we introduce the machine learning core concepts, including supervised vs. unsupervised learning, prediction, inference, regression, classification, model selection and evaluation. 

## Learning Objectives
By the end of this section, we'll be able to:  

1. Characterize and contrast supervised and unsupervised learning problems   
1. Characterize and contrast supervised and unsupervised learning problems   
3. Describe and derive the linear model used in regression and classification settings  
4. Distinguish parametric and non-parametric methods of regression and classification   

No prior knowledge of linear algebra, statistical learning, multivariate calculus or Bayesian statistics is assumed, but some background would be useful. For some, especially practitioners currently in industry, it may be appropriate to skip ahead to linear classification. If you are like me (and I know I am), this section is intended to refresh, reinforce, stimulate and provoke a working and portable intuition for classification methods specifically, and statistical learning in general.  

## Machine Learning Introduction
The term 'machine learning' was first coined in 1959 by Arthur Samuel as "the field of study that gives computers the ability to learn without being explicitly programmed." [@5392560] Tom Mitchel, a computer scientist and professor at Carnegie Mellon University (CMU), provided a more formal definition: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. [@Mitchell1997]. Machine learning is about learning from data in order to draw inferences or make predictions.

*Most* machine learning problems fall into one of two categories: *supervised* or *unsupervised*. Let's distinguish these broad categories.

### Supervised Learning  
In supervised learning problems, we are given a training data set with inputs or *predictors* and the output, or *response* variable. Our objective is to *learn* the relationships between the predictors and the response so that we can accurately predict responses on unseen data (*prediction*) or better understand the relationships between the predictors and response (*inference*). 

More formally, our goal is to learn a **hypothesis** function $h: X \mapsto Y$ so that $h(x)$ is a 'good' predictor for the corresponding value of $y$.

Supervised learning problems are categorized into *'regression'* and *'classification'* problems. Regression problems involve quantitative or continuous response variables. Real-world examples include: 

* Predict the price of a stock in 6 months from now, on the basis of company performance measures and economic data.  
* Predict automobile mileage per gallon based upon design characteristics such as weight, horsepower, engine characteristics, passenger compartment configuration, and size.    
* Predict executive salaries based upon industry, department, candidate experience, and industry salary data. 

Classification problems deal with discrete or qualitative responses. Examples include:  

* Identify the digits in a handwritten ZIP code from a digitized image.  
* Predict whether a tumor is benign or malignant on the basis tumor size and imaging data.   
* Predict whether two members on an online dating site are a match on the basis of personal attributes, priorities, values, lifestyle data, and preferences.  

Classification problems may be further categorized in terms of the number of qualitative responses. For instance a two classification problem is known as a **binary** **classification** problem. The two prediction examples above would be characterized as binary classification problems. The hand writing recognition problem is an example of a **multi-label** **classification** problem. 

### Unsupervised Learning
In contrast, *unsupervised* learning involves data sets with predictors and no associated response variable.  The task is somewhat more complex as we attempt to discover patterns and relationships in the data without the presence of a *"supervising"* response variable. Examples of real-world unsupervised learning problems include:

* In a market segmentation study, cluster potential customers based upon zip-code, family income, and shopping habits.   
* Automatically determine the features required for classification from raw, unlabeled input data.  
* Reduce the dimensions required for classification or regression by mapping inputs into a lower-dimensional predictor space.   

Supervised learning is the focus of this series.  Next, we'll discuss supervised learning model representation, regression and classification.  

## Model Representation
Consider a quantitative response $Y$ and $p$ different predictors, $X_1, X_2, \dots X_p$.  We can write the relationship between the predictors and the response as:
$$Y=f(x)+\epsilon$$
Here, $f$ is some fixed but unknown function of $X_1,\dots,X_P$, and $\epsilon$ is a random *error* *term*, which is independent of $X$ and has a zero mean. 

In general, we seek to learn an function $\hat{f}(x)$ that renders predictions $\hat{Y}$. Since errors average to zero, we can write this relationship as:
$$\hat{Y}=\hat{f}(x)$$
For the classification setting, consider a binary response $Y$, coded as 0 or 1. For instance, we may be classifying a tumor as benign (0) or malignant (1) based upon tumor size and imaging data. We seek a $f(X)$ that renders $Pr(G=1|X=x)$, the probability that a tumor is malignant. The series is about the concepts and techniques used to estimate and evaluate $f$.

`r h <- 'Why Do We Estimate $f$?'`
### `r h`  
We estimate $f$ for two reasons: *prediction* and *inference*. When prediction is our goal,$f$ is often treated as a *black* *box*. As long as $f$ yields accurate predictions for $Y$, one is not *generally* concerned with the exact form of $f$. 

#### Prediction
Prediction accuracy stems from two elements: *reducible* and *irreducible* error. Reducible error is that which we seek to minimize using statistical methods. Reducible error is extant because $\hat{f}$ is not a perfect estimate for $f$. Yet, we call this reducible because we can improve our estimate of $f$ with appropriate statistical techniques. Irreducible error, in contrast, exists because $f$ is also a function of $\epsilon$, which, by definition, can't be predicted using $X$. Irreducible error emerges from elements outside of the model and variables which aren't measured. Though they may have a marginal effect on the prediction, such unmeasured elements are not included in the model. For instance, the probability of a positive prediction in a healtcare setting might vary for a given patient, on a given day, depending upon manufacturing variation in the components of the ICG machine taking measurements. Our focus is the application of techniques we can use to minimize *reducible* error and maximize prediction accuracy.

#### Inference 
Often we wish to understand the ways in which $Y$ is affected by a predictor space $X_1,\dots X_p$ Our goal, in this case, isn't necessarily to predict $Y$ based upon its predictors. Rather, we seek to understand the relationships between predictors and the response. Can the relationship be modeled as a linear function or is the mapping more complex? How does the change in predictors effect $Y$? In such cases, we can't afford to treat $f$ as a *black* *box*. Unlike prediction, We must know its exact form. 

`r h <- 'How Do We Estimate $f$?'`
### `r h` 
Given a set of training data, our task is to apply a statistical learning method which will allow us to find a function $\hat{f}$ such that $Y \approx \hat{f}(X)$ for any observation $(X,Y)$. Generally speaking, statistical methods can be characterized as either *parametric* or *non-parametric*. 

#### Parametric Methods
Parametric learning methods take a two step model-based approach.

1. Make an assumption about the functional form of $f$. We may say, for instance, that $f$ is linear whereby:
$$f(x)=\beta_0+\beta_1X_1+\beta_2X_2+\dots+\beta_pX_p\label{step1}$$
This substantially reduces our problem from estimating a $p$-dimensional function $f(X)$ to estimating just the $p+1$ coefficients $\beta_0,\beta_1, \dots ,\beta_p.$  
2. Estimate the *parameters* by fitting or training the model to find values such that:
$$Y \approx \beta_0+\beta_1X_1+\beta_2X_2+\dots+\beta_pX_p.$$
Ordinary least squares is the most common approach for estimating the parameters in $\ref{step1}$ We'll illustrate this approach as we develop linear models for regression and classification.

As stated above, parametric methods reduce the problem of estimating $f$ down to estimating a set of parameters. But this requires us to assume a functional form for $f$ that may or may not be true. Selecting the wrong model will result in a poor estimation of $f$.

#### Non-Parametric Methods
Non-parametric models make no explicit assumptions about the form of $f$. Rather, they seek to find a 'goldilocks' estimation that closely fits the data without overfitting. Since no functional form is assumed, $f$ can take a wider range of shapes, but this comes at a cost. Non-parametric methods tend to require a far greater number of training observations to estimate $f$ than do parametric models.

We will examine non-parametric methods later in the series. Now, we apply parametric methods to estimating $f$ in regression and classification settings. 

`r h <- 'How Do We Assess $\\hat{f}$?'`
## `r h` 
In this series, we will be exploring a range of parametric and non-parametric supervised learning methods.  We do so because there is no single method that dominates all others over all possible data sets. Therefore, we need a way to measure how well a method's predictions actually match the observed data. In this section, we explore ways to quantify the degree to which predictions match the true responses in both regression and classification contexts. 

### Model Assessment in Regression  
In the regression setting, the most widely-used model assessment measure is the **mean** **squared** **error** (MSE), given by
$$MSE = \frac{1}{2n}\displaystyle\sum_{i=1}^n(y_i - \hat{f}(x_i))^2,$$
where $\hat{f}(x_i)$ is the prediction that $f$ renders for the $i$th observation. Those familiar with this metric will have noticed that we are actually dividing the mean squared error by two.  This is a convenience for the computation of the *gradient descent* as the derivative term of the square function will cancel out the 1/2 term. Including the 1/2 term doesn't affect the minimalization problem. More on this later.

### Model Assessment in Classification
