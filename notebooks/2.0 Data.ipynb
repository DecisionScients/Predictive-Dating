{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from shared import directories\n",
    "from shared import filenames\n",
    "from shared import variables\n",
    "\n",
    "sys.path.append(directories.ANALYSIS_DIR)\n",
    "import description\n",
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Obtain raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 195 entries, iid to amb5_3\n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    df = pd.read_csv(\"../data/raw/Speed Dating Data.csv\",\n",
    "                     encoding=\"Latin-1\", low_memory=False)\n",
    "    df_columns = pd.read_csv(\"../data/external/columns.csv\",\n",
    "                     encoding=\"Latin-1\", low_memory=False)\n",
    "    df_universities = pd.read_csv(\"../data/external/universities.csv\",\n",
    "                     encoding=\"Latin-1\", low_memory=False)\n",
    "                             \n",
    "    return(df, df_columns, df_universities)\n",
    "df, df_columns, df_universities = get_data()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.0 Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>8315</td>\n",
       "      <td>259</td>\n",
       "      <td>Business</td>\n",
       "      <td>521</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undergra</th>\n",
       "      <td>4914</td>\n",
       "      <td>241</td>\n",
       "      <td>UC Berkeley</td>\n",
       "      <td>107</td>\n",
       "      <td>3464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn_sat</th>\n",
       "      <td>3133</td>\n",
       "      <td>68</td>\n",
       "      <td>1,400.00</td>\n",
       "      <td>403</td>\n",
       "      <td>5245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuition</th>\n",
       "      <td>3583</td>\n",
       "      <td>115</td>\n",
       "      <td>26,908.00</td>\n",
       "      <td>241</td>\n",
       "      <td>4795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>8299</td>\n",
       "      <td>269</td>\n",
       "      <td>New York</td>\n",
       "      <td>522</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>7314</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>4279</td>\n",
       "      <td>261</td>\n",
       "      <td>55,080.00</td>\n",
       "      <td>124</td>\n",
       "      <td>4099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>8289</td>\n",
       "      <td>367</td>\n",
       "      <td>Finance</td>\n",
       "      <td>202</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique          top freq  missing\n",
       "field     8315    259     Business  521       63\n",
       "undergra  4914    241  UC Berkeley  107     3464\n",
       "mn_sat    3133     68     1,400.00  403     5245\n",
       "tuition   3583    115    26,908.00  241     4795\n",
       "from      8299    269     New York  522       79\n",
       "zipcode   7314    409            0  355     1064\n",
       "income    4279    261    55,080.00  124     4099\n",
       "career    8289    367      Finance  202       89"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df.select_dtypes(include=['object'])\n",
    "description.describe_qual_df(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Categorical Data Processing Plan\n",
    "The following variables must be converted to numeric:\n",
    "1. mn_sat \n",
    "2. tuition\n",
    "3. income \n",
    "\n",
    "In terms of missing data:\n",
    "1. Field and career are 'form filled' and are subject to misspellings and omission. The field_cd and career_c fields will\n",
    "be used instead.\n",
    "2. There are no other opportunities for data imputation for the categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Convert categorical numbers to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mn_sat'] = df['mn_sat'].str.replace(\",\",\"\").astype(float)\n",
    "df['income'] = df['income'].str.replace(\",\",\"\").astype(float)\n",
    "df['tuition'] = df['tuition'].str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Quantitative Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.0 Quantitative Data Audit\n",
    "Looking preference and rating variables that require normalization due to different scoring instructions by wave "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Quantitative Data Processing Plan\n",
    "1. id: Impute missing id.\n",
    "2. gender: Recode as Categorical Variables\n",
    "3. race: Recode as Categorical Variables\n",
    "4. pid: Impute 10 missing pid values.\n",
    "5. Change partner to pid and pid to piid for clarity.\n",
    "6. field_cd: Update field_cd for 'Operations Research' to 8 for Business/Econ/Finance\n",
    "7. normalize all ratings and preferences to 100 point scale.\n",
    "\n",
    "Encoding: Use descriptive encoding for target variables\n",
    "1. decision\n",
    "2. decision_o\n",
    "3. match\n",
    "\n",
    "Encoding cross-references\n",
    "Create label cross reference tables so that they are available for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = pd.read_csv(\"../data/external/columns.csv\",\n",
    "                 encoding=\"Latin-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1.1 Missing id\n",
    "Since each subject has a unique iid, we can impute the missing id by finding the associated id for the same iid in another observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid = df.loc[df['id'].isna()]['iid'].tolist()\n",
    "id = df.loc[df['iid'] == iid]['id'].unique()\n",
    "df.loc[(df.id.isna()), 'id'] = id[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.2  Recode Gender \n",
    "Recode gender to \"Male\" and \"Female\" for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 195 entries, iid to amb5_3\n",
      "dtypes: float64(177), int64(12), object(6)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df['gender'] = np.where(df['gender'] == 0, \"Female\", \"Male\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.3 Race Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = np.where(df['race'] == 1, 'Black',\n",
    "                     np.where(df['race'] == 2, 'Caucasian',\n",
    "                             np.where(df['race'] == 3, \"Latino\",\n",
    "                                     np.where(df['race'] == 4, \"Asian\",\n",
    "                                             np.where(df['race'] == 5, \"Native American\", \"Other\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race_o'] = np.where(df['race_o'] == 1, 'Black',\n",
    "                     np.where(df['race_o'] == 2, 'Caucasian',\n",
    "                             np.where(df['race_o'] == 3, \"Latino\",\n",
    "                                     np.where(df['race_o'] == 4, \"Asian\",\n",
    "                                             np.where(df['race_o'] == 5, \"Native American\", \"Other\")))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1.2 Missing piid and Column Rename\n",
    "First, rename partner to pid and pid to piid for clarity. Now we have 10 missing piid's - the partner's iid number. As it turns out, all 10 are for pid number 7, from wave 5. We can obtain the missing piid from the iid for id number 7 of the same wave. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'pid': 'piid'})\n",
    "df = df.rename(columns={'partner':'pid'})\n",
    "wave_pid = df.loc[df['piid'].isna()][['wave','pid']].drop_duplicates()\n",
    "piid = df.loc[(df['wave'] == wave_pid.wave.tolist()) & (df['id'] == wave_pid.pid.tolist())]['iid'].drop_duplicates().tolist()\n",
    "df.loc[(df.piid.isna()), 'piid'] = piid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.3 Update Field_Cd for Operations Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['field'] == 'Operations Research', 'field_cd'] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.4 Career_c Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['career'] == 'lawyer', 'career_c'] = 1\n",
    "df.loc[df['career'] == 'law', 'career_c'] = 1\n",
    "df.loc[df['career'] == 'Economist', 'career_c'] = 7\n",
    "df.loc[df['career'] == 'tech professional', 'career_c'] = 15\n",
    "df.loc[df['career'].isnull(), 'career_c'] = 10 # NaNs converted to undecided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.5 Convert select binary variables to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['b_dec'] = df['dec']\n",
    "df['b_dec_o'] = df['dec_o']\n",
    "df['b_match'] = df['match']\n",
    "df['dec'] = np.where(df['dec']==0, 'No', 'Yes')\n",
    "df['dec_o'] = np.where(df['dec_o']==0, 'No', 'Yes')\n",
    "df['match'] = np.where(df['match']==0, 'Not Matched', 'Matched')\n",
    "df['condtn'] = np.where(df['condtn']==1, 'Limited Choice', 'Extensive Choice')\n",
    "df['samerace'] = np.where(df['samerace']==1, 'Same Race', 'Not Same Race')\n",
    "df['met'] = np.where(df['met']==1, 'Met', 'Not Met')\n",
    "df['met_o'] = np.where(df['met_o']==1, 'Met', 'Not Met')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.6 Difference in Age [Male-Female]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_diff'] = df['age']-df['age_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.7 Encoding Cross-Reference Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 0 to 8377\n",
      "Columns: 200 entries, iid to field_label\n",
      "dtypes: float64(174), int64(10), object(16)\n",
      "memory usage: 12.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Field_cd\n",
    "code = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,]\n",
    "value = ['Law','Math','Social Science, Psychologist','Medical Science, Pharmaceuticals, and Bio Tech','Engineering',\n",
    "         'English/Creative Writing/ Journalism','History/Religion/Philosophy','Business/Econ/Finance',\n",
    "         'Education, Academia','Biological Sciences/Chemistry/Physics','Social Work','Undergrad/undecided',\n",
    "         'Political Science/International Affairs','Film','Fine Arts/Arts Administration','Languages',\n",
    "         'Architecture','Other']\n",
    "df_labels = pd.DataFrame({'field_cd': code, 'field_label':value})\n",
    "df = df.merge(df_labels, how='left')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 0 to 8377\n",
      "Columns: 201 entries, iid to goal_label\n",
      "dtypes: float64(174), int64(10), object(17)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Goal\n",
    "code = [1,2,3,4,5,6]\n",
    "value = ['Seemed like a fun night out', 'To meet new people', 'To get a date', 'Looking for a serious relationship',\n",
    "         'To say I did it', 'Other']\n",
    "df_labels = pd.DataFrame({'goal': code, 'goal_label':value})\n",
    "df = df.merge(df_labels, how='left')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date\n",
    "code = [1,2,3,4,5,6,7]\n",
    "value = ['Several times a week','Twice a week','Once a week','Twice a month','Once a month','Several times a year',\n",
    "         'Almost never']\n",
    "df_labels = pd.DataFrame({'date': code, 'date_label':value})\n",
    "df = df.merge(df_labels, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go_out\n",
    "code = [1,2,3,4,5,6,7]\n",
    "value = ['Several times a week','Twice a week','Once a week','Twice a month','Once a month','Several times a year',\n",
    "         'Almost never']\n",
    "df_labels = pd.DataFrame({'go_out': code, 'go_out_label':value})\n",
    "df = df.merge(df_labels, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Career_c\n",
    "code = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "value = ['Lawyer','Academic/Research','Psychologist','Doctor/Medicine','Engineer','Creative Arts/Entertainment',\n",
    "         'Banking/Consulting/Finance/Marketing/Business/CEO/Entrepreneur/Admin','Real Estate',\n",
    "         'International/Humanitarian Affairs','Undecided','Social Work','Speech Pathology','Politics',\n",
    "         'Pro sports/Athletics','Other','Journalism','Architecture']\n",
    "df_labels = pd.DataFrame({'career_c': code, 'career_label':value})\n",
    "df = df.merge(df_labels, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length\n",
    "code = [1,2,3]\n",
    "value = ['Too Little', 'Too Much', 'Just Right']\n",
    "df_labels = pd.DataFrame({'length': code, 'length_label':value})\n",
    "df = df.merge(df_labels, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 0 to 8377\n",
      "Columns: 206 entries, iid to numdat_2_label\n",
      "dtypes: float64(174), int64(10), object(22)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Numdat_2\n",
    "code = [1,2,3]\n",
    "value = ['Too Few', 'Too Many', 'Just Right']\n",
    "df_labels = pd.DataFrame({'numdat_2': code, 'numdat_2_label':value})\n",
    "df = df.merge(df_labels, how='left')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.8 Add Partner  Field and Same Field Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields = df[['iid', 'field_cd']]\n",
    "df_fields = df_fields.rename(columns={'iid': 'piid', 'field_cd':'field_cd_o'})\n",
    "df_fields = df_fields.drop_duplicates()\n",
    "df = pd.merge(df,df_fields, on='piid', how='left')\n",
    "df['same_field'] = np.where(df['field_cd']==df['field_cd_o'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.9 Add Partner Career and Same Career Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_career = df[['iid', 'career_c']]\n",
    "df_career = df_career.rename(columns={'iid': 'piid', 'career_c':'career_c_o'})\n",
    "df_career = df_career.drop_duplicates()\n",
    "df = pd.merge(df,df_career, on='piid', how='left')\n",
    "df['same_career'] = np.where(df['career_c']==df['career_c_o'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.9 Add Partner Career Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "value = ['Lawyer','Academic/Research','Psychologist','Doctor/Medicine','Engineer','Creative Arts/Entertainment',\n",
    "         'Banking/Consulting/Finance/Marketing/Business/CEO/Entrepreneur/Admin','Real Estate',\n",
    "         'International/Humanitarian Affairs','Undecided','Social Work','Speech Pathology','Politics',\n",
    "         'Pro sports/Athletics','Other','Journalism','Architecture']\n",
    "df_labels = pd.DataFrame({'career_c_o': code, 'career_label_o':value})\n",
    "df = df.merge(df_labels, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.10 Add Partner Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income = df[['iid', 'income']]\n",
    "df_income = df_income.rename(columns={'iid': 'piid', 'income':'income_o'})\n",
    "df_income = df_income.drop_duplicates()\n",
    "df = pd.merge(df,df_income, on='piid', how='left')\n",
    "df['income_diff'] = df['income'] - df['income_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.11 Add Median SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat = df[['iid', 'mn_sat']]\n",
    "df_sat = df_sat.rename(columns={'iid': 'piid', 'mn_sat':'ms_sat_o'})\n",
    "df_sat = df_sat.drop_duplicates()\n",
    "df = pd.merge(df,df_sat, on='piid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.12 Add Partner Tuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuition = df[['iid', 'tuition']]\n",
    "df_tuition = df_tuition.rename(columns={'iid': 'piid', 'tuition':'tuition_o'})\n",
    "df_tuition = df_tuition.drop_duplicates()\n",
    "df = pd.merge(df,df_tuition, on='piid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.13 Standardize University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 0 to 8377\n",
      "Columns: 216 entries, iid to undergra_cd\n",
      "dtypes: float64(180), int64(10), object(26)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df,df_universities, on='undergra', how='left')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.14 Standardize SAT Scores by University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.undergra_cd == 'Wesleyan University','mn_sat'] = 1360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.15 Add University Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_sat = df['mn_sat'].drop_duplicates()\n",
    "mn_sat = mn_sat.dropna()\n",
    "mn_sat = pd.DataFrame({'mn_sat':sorted(mn_sat, reverse=True)})\n",
    "mn_sat['uni_rank'] = mn_sat.rank(ascending=False)\n",
    "mn_sat['top_pct'] = mn_sat['uni_rank'] / max(mn_sat['uni_rank']) * 100\n",
    "mn_sat['uni_rank'] = np.where(mn_sat['top_pct']<6, 5,\n",
    "                         np.where(mn_sat['top_pct']<11, 10,\n",
    "                                  np.where(mn_sat['top_pct']<21, 20,\n",
    "                                           np.where(mn_sat['top_pct']<51, 50, 100))))\n",
    "mn_sat = mn_sat.drop(['top_pct'], axis=1)\n",
    "df = pd.merge(df, mn_sat, on='mn_sat', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Normalize Ratings and Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3.1 Normalize Ratings of Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx_norm = [13,14,15,16,17,18,20,21,22,23,28,29,30,31,32,33]\n",
    "for i in idx_norm:\n",
    "    columns = list(df_columns[df_columns['cat no.']==i]['column'])\n",
    "    ttl = df[columns].sum(axis=1)\n",
    "    df2 = df[columns].div(other=ttl, axis=0)\n",
    "    df2 = df2 * 100\n",
    "    df.update(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Success Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4.1. Success Rates for Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yes_rate'] = df.groupby('iid')['b_dec_o'].transform(lambda x:x.mean())\n",
    "df['match_rate'] = df.groupby('iid')['b_match'].transform(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data \n",
    "Save training, validation and test sets in an interim directory for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(df, directory, filename):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        if isinstance(filename, str):\n",
    "            if not os.path.isdir(directory):\n",
    "                os.mkdir(directory)\n",
    "            df.to_csv(os.path.join(directory, filename),\n",
    "                      index=False, index_label=False)\n",
    "            return(True)\n",
    "        else:\n",
    "            return(False)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(df, \"../data/interim\", 'interim.csv')\n",
    "write(df_labels, '../data/external', 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
